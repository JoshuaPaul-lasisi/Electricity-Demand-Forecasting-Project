{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Electricity Demand Forecasting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Project Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project focuses on forecasting electricity demand (total load) and predicting electricity prices using historical energy generation and weather data. Accurate forecasting is crucial for efficient grid management, minimizing energy wastage, and optimizing power generation to meet demand at the lowest cost. The two datasets used provide information on energy production from various sources and detailed weather conditions, making it possible to explore the impact of external factors such as weather on energy demand and prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to build a model that can predict two main targets:\n",
    "\n",
    "- **Total electricity load (demand)**: This helps energy producers adjust generation in real-time.\n",
    "\n",
    "- **Electricity price**: Accurately predicting prices helps utilities and businesses with cost planning and optimization.\n",
    "\n",
    "\n",
    "The models developed should help improve planning and operational decisions in the energy sector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Dataset Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using two main sets of data:\n",
    "\n",
    "- **Energy Dataset**: This contains information about how much electricity was generated from different sources (like solar, wind, coal), forecasts (predictions made earlier), actual electricity loads, and energy prices.\n",
    "\n",
    "\n",
    "- **Weather Dataset**: This includes weather information like temperature, pressure, humidity, wind speed, and conditions (e.g., clear, rainy) for different cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_data(energy_path, weather_path):\n",
    "    \"\"\"\n",
    "    Load the energy and weather datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    energy_path (str): Path to the energy dataset.\n",
    "    weather_path (str): Path to the weather dataset.\n",
    "    \n",
    "    Returns:\n",
    "    energy (DataFrame): Energy dataset.\n",
    "    weather (DataFrame): Weather dataset.\n",
    "    \"\"\"\n",
    "    energy = pd.read_csv(energy_path)\n",
    "    weather = pd.read_csv(weather_path)\n",
    "    return energy, weather\n",
    "\n",
    "def clean_data(energy, weather):\n",
    "    \"\"\"\n",
    "    Clean the datasets by filling missing values and dropping empty columns.\n",
    "    \n",
    "    Parameters:\n",
    "    energy (DataFrame): Energy dataset.\n",
    "    weather (DataFrame): Weather dataset.\n",
    "    \n",
    "    Returns:\n",
    "    data (DataFrame): Cleaned and merged dataset.\n",
    "    \"\"\"\n",
    "    # Drop empty columns\n",
    "    energy = energy.drop(columns=['forecast wind offshore eday ahead', 'generation hydro pumped storage aggregated'])\n",
    "    energy = energy.ffill()  # Fill missing values\n",
    "    weather = weather.ffill()\n",
    "\n",
    "    # Convert time columns to datetime\n",
    "    energy['time'] = pd.to_datetime(energy['time'], utc=True)\n",
    "    weather['dt_iso'] = pd.to_datetime(weather['dt_iso'], utc=True)\n",
    "\n",
    "    # Merge datasets\n",
    "    data = pd.merge(energy, weather, left_on='time', right_on='dt_iso', how='inner')\n",
    "    return data\n",
    "\n",
    "def feature_engineering(data):\n",
    "    \"\"\"\n",
    "    Create new time-based features and select relevant columns for modeling.\n",
    "    \n",
    "    Parameters:\n",
    "    data (DataFrame): Cleaned dataset.\n",
    "    \n",
    "    Returns:\n",
    "    X (DataFrame): Feature matrix.\n",
    "    y_price (Series): Target variable for price.\n",
    "    y_load (Series): Target variable for load.\n",
    "    \"\"\"\n",
    "    # Create time-based features\n",
    "    data['hour'] = data['time'].dt.hour\n",
    "    data['day'] = data['time'].dt.day\n",
    "    data['month'] = data['time'].dt.month\n",
    "    data['weekday'] = data['time'].dt.weekday\n",
    "\n",
    "    # Select features and target\n",
    "    features = ['generation biomass', 'generation fossil gas', 'generation solar', 'generation wind onshore', \n",
    "                'total load actual', 'temp', 'pressure', 'humidity', 'wind_speed', 'hour', 'weekday']\n",
    "    X = data[features]\n",
    "    y_price = data['price actual']\n",
    "    y_load = data['total load actual']\n",
    "    return X, y_price, y_load\n",
    "\n",
    "def train_models(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train Random Forest and Gradient Boosting models.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train (DataFrame): Training feature matrix.\n",
    "    y_train (Series): Training target variable.\n",
    "    \n",
    "    Returns:\n",
    "    rf (RandomForestRegressor): Trained Random Forest model.\n",
    "    gb (GradientBoostingRegressor): Trained Gradient Boosting model.\n",
    "    \"\"\"\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    gb = GradientBoostingRegressor(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    gb.fit(X_train, y_train)\n",
    "    return rf, gb\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model using Mean Squared Error and R-squared metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    model (Regressor): Trained model.\n",
    "    X_test (DataFrame): Test feature matrix.\n",
    "    y_test (Series): Test target variable.\n",
    "    \n",
    "    Returns:\n",
    "    mse (float): Mean Squared Error.\n",
    "    r2 (float): R-squared score.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    energy_path = './datasets/energy_dataset.csv'\n",
    "    weather_path = './datasets/weather_features.csv'\n",
    "    energy, weather = load_data(energy_path, weather_path)\n",
    "    \n",
    "    # Clean and preprocess data\n",
    "    data = clean_data(energy, weather)\n",
    "    X, y_price, y_load = feature_engineering(data)\n",
    "    \n",
    "    # Split data\n",
    "    X_train_price, X_test_price, y_train_price, y_test_price = train_test_split(X, y_price, test_size=0.2, random_state=42)\n",
    "    X_train_load, X_test_load, y_train_load, y_test_load = train_test_split(X, y_load, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train models\n",
    "    rf_price, gb_price = train_models(X_train_price, y_train_price)\n",
    "    rf_load, gb_load = train_models(X_train_load, y_train_load)\n",
    "    \n",
    "    # Evaluate models\n",
    "    mse_rf_price, r2_rf_price = evaluate_model(rf_price, X_test_price, y_test_price)\n",
    "    mse_gb_price, r2_gb_price = evaluate_model(gb_price, X_test_price, y_test_price)\n",
    "    \n",
    "    mse_rf_load, r2_rf_load = evaluate_model(rf_load, X_test_load, y_test_load)\n",
    "    mse_gb_load, r2_gb_load = evaluate_model(gb_load, X_test_load, y_test_load)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Random Forest Price - MSE: {mse_rf_price}, R2: {r2_rf_price}\")\n",
    "    print(f\"Gradient Boosting Price - MSE: {mse_gb_price}, R2: {r2_gb_price}\")\n",
    "    print(f\"Random Forest Load - MSE: {mse_rf_load}, R2: {r2_rf_load}\")\n",
    "    print(f\"Gradient Boosting Load - MSE: {mse_gb_load}, R2: {r2_gb_load}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
